
\subsection{Network Telemetry}

Monitoring mechanisms were designed to provide comprehensive network-wide visibility. The visibility refers to (i) network coverage (in terms of monitoring metrics), (ii) granularity, and (iii) freshness of collected data. The broader is the visibility tripod (i.e. coverage, granularity, freshness), the better the network operators tasks are, such as (i) schedule network resources; (ii) measuring the performance of network services; (iii) plan the network operation (e.g. traffic engineering); (iv) predict or track network events (e.g. network attacks); and (v) identify fault, anomalies or policy violations.

The network operator's ability to promptly troubleshoot network events is currently limited to the network visibility provided by conventional monitoring approaches. As an example of such limitation, suppose the quality of experience (QoE) of a multimedia application (e.g. streaming of VR\footnote{Virtual Reality} content) worsen in a given IP network. From the network operator perspective, it is hard to know whether this is a network problem-related issue (e.g. link congestion) or a specific problem in the application layer (e.g. bit rate codec).  
%
In this example, the monitoring approach has fallen short of timely providing the network information required to identify the problem. 
%
There are a few reasons for that: (i) low-frequency data fetching -- i.e., poll-based mechanisms (e.g. SNMP) are insufficient to keep up with the data rate modern data analyzer requires; (ii) high overhead and inaccuracy -- i.e., passive/active measurements might consume too much network resources and might collect redundant information. Further, active measurements can unpredictably interfere with the user traffic; and (iii) little or no flexibility to monitor any performance metric -- i.e., data might come from many sources at any place/layer with any granularity. This is especially hard to achieve considering conventional data planes and existing network monitoring protocols (e.g. NetFlow). 

Network telemetry is a mainstream technical term to refer to the newest techniques of data collection and consumption \cite{rfc-ntf}. It is expected that network telemetry improves network visibility and addresses the aforementioned shortcomings of conventional monitoring approaches. One of the key differences to the conventional monitoring techniques is that network telemetry assumes an intelligent entity in the center of a closed control loop, while in the conventional approach there is the network operator. This shift in network monitoring operation started with the emergence of SDN. SDN has enabled query-oriented monitoring approaches, which integrate both the telemetry and analysis steps into a closed-loop to enhance monitoring efficiency. Recent efforts on this domain have focused on (i) the optimization of probing frequency ~\cite{noms14-payless,im17-DecentralizedMonitoring} and on (ii) the optimization of query planning (e.g. PathQueries~\cite{nsdi16-PathQueries}, and SNAP~\cite{sigcomm16-snap}). Other studies such as DREAM~\cite{sigcomm14-dream}, SCREAM~\cite{conext15-scream}, and SONATA~\cite{sigcomm18-sonata} have focused on building dynamic monitoring planning mechanisms over time. 
%
Network telemetry is expected to support, with real-time network information, emerging monitoring application -- such as the ones based on machine learning techniques, which are known to be data-intensive in-takers.


Despite significant advances made on network monitoring approaches, there are still challenges towards an autonomous, closed-control loop operation. Part of the challenge consists of wisely gathering telemetry data from the network in order to build a comprehensive network-wide view. In this direction, IETF is currently working on a network telemetry architecture, consisting of three main components: (i) data sources, (ii) data collectors, and (iii) data analyzers\footnote{To further information, the interested reader is referred to \cite{rfc-ntf}.}. To achieve the desired network visibility, there are a few characteristics that are essential in this new network monitoring approach: (i) continuous push-based streaming of telemetry information to data analyzers (instead of relying on polling mechanisms); 
%
(ii) in-network capacity to handle and aggregate a high volume of telemetry data (reducing the overhead and inaccuracy of duplicated data); 
%
(iii) in-network customization of programmable data planes. 
%
This allows monitoring probes to be deployed at flexible locations and to be dynamically adjusted, e.g. the sampling rate in which telemetry data is collected. More importantly, telemetry data can be directly collected and exported by the data plane of any device on the forwarding path. By dynamically tuning how telemetry data is collected, network resources can be efficiently used (which reduces the impact on the network infrastructure) and enhance network visibility (which increases the accuracy of monitoring applications). 