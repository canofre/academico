% Artigo escrito em junho de 2007
% Por Caroline Vicentini e Ronaldo Canofre
% Revisao da Professora Tutora Andrea Charao
\documentclass[12pt]{article}

\usepackage{ref/sbc-template}
\usepackage{graphicx,url}
\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  
\usepackage{xspace}
     
\sloppy

\title{Compara\c{c}\~{a}o entre Abordagens de Paraleliza\c{c}\~{a}o para o Problema do Jogo da Vida}

\author{Daniel Michelon de Carli\inst{1,2}, Eduardo Spolaor Mazzanti\inst{1,2,3},  Rodrigo Dewes\inst{1},\\Ronaldo Canofre M. dos Santos \inst{1,3}, Valdir Stumm Junior\inst{1}, Andrea Schwertner Char\~{a}o\inst{3} }

\address{Acadêmico do Curso de Ci\^{e}ncia da Computa\c{c}\~{a}o
\nextinstitute GPIM - Grupo de Processamento de Informa\c{c}\~{a}o Multim\'{i}dia
\nextinstitute Programa de Educa\c{c}\~{a}o Tutorial (PET) -- Curso de Ci\^{e}ncia da Computa\c{c}\~{a}o\\
  Universidade Federal de Santa Maria (UFSM)
  \email{\{dcalri, mazzanti, dewes, canofre, junior, andrea\}@inf.ufsm.br}
}

%\newcommand{\software}{\textit{software}\xspace}
\newcommand{\site}{\textit{site}\xspace}


%%=============================================================================
%% Definições para posicionar figuras nas páginas
%%=============================================================================

\renewcommand{\topfraction}{1}
\setcounter{topnumber}{5}
\renewcommand{\bottomfraction}{1}
\setcounter{bottomnumber}{5}
\renewcommand{\textfraction}{0}
\setcounter{totalnumber}{10}


\begin{document}

\maketitle

%\begin{abstract}
%\end{abstract}

     
\begin{resumo}
O ``Jogo da Vida'' é um exemplo clássico de autômato celular que simula a evolução de seres vivos em um dado espaço ao longo do tempo. Dependendo dos dados de entrada, o tempo de processamento de uma simulação pode ser elevado. Neste artigo, apresenta-se uma comparação entre duas abordagens de paralelização para o problema do Jogo da Vida, visando a redução do tempo de simulação através do uso de múltiplos computadores em paralelo. Ambas abordagens utilizam o padrão MPI (Message Passing Interface) para implementação da troca de mensagens entre os computadores cooperantes, porém com diferentes estratégias de distribuição do trabalho e comunicação entre os processos. Os resultados obtidos evidenciam que a paralelização deste problema não é trivial, mas que em certos casos é possível obter ganhos de desempenho com ambas abordagens. Além disso, mostra-se que o desempenho de uma das implementações é ligeiramente superior à outra em todos os casos considerados.
\end{resumo}


\section{Introdu\c{c}\~{a}o}
O Jogo da Vida (\emph{Game of Life}) \'{e} um aut\^{o}mato celular desenvolvido pelo matem\'{a}tico brit\^{a}nico John Horton Conway em 1970. Foi criado com o objetivo de reproduzir as altera\c{c}\~{o}es e mudan\c{c}as em grupos de seres vivos com passar do tempo, sendo aplicado em diversas \'{a}reas da ci\^{e}ncia, como na biologia, na matem\'{a}tica, na economia, entre outras~\cite{wiki}.

Este aut\^{o}mato \'{e} um jogo sem jogadores. Ele recebe como dados de entrada uma população de seres dispostos sobre uma grade bi-dimensional (matriz) e a quantidade de tempo pelo qual essa popula\c{c}\~{a}o ir\'{a} interagir. A cada itera\c{c}\~{a}o (passo de tempo), aplica-se um conjunto de regras simples \`{a} matriz contendo os dados da ``gera\c{c}\~{a}o atual'', produzindo assim uma ``nova gera\c{c}\~{a}o''.

O Jogo da Vida, bem como outros outros autômatos celulares, pode levar a um longo tempo de processamento para dados de entrada que possuam um grande n\'{u}mero de gera\c{c}\~{o}es e/ou uma matriz de consider\'{a}vel tamanho. A fim de reduzir este tempo, pode se utilizar o processamento paralelo.

A pr\'{a}tica da programa\c{c}\~{a}o paralela pode ser considerada como a divis\~{a}o de um programa seqüencial em partes menores que possam ser executadas de forma simult\^{a}nea por processadores diferentes~\cite{wilk}. Com isso é possível reduzir o tempo total de processamento de um programa e permitir sua execu\c{c}\~{a}o em um tempo aceit\'{a}vel, contar com a disponibilidade de mais recursos como mem\'{o}ria e capacidade de processamento e, também, diminuir custos atrav\'{e}s da utiliza\c{c}\~{a}o de um grande n\'{u}mero de esta\c{c}\~{o}es de trabalho ao inv\'{e}s de um super computador.

Neste contexto, este trabalho tem como objetivo comparar duas implementa\c{c}\~{o}es diferentes de paraleliza\c{c}\~{a}o de aut\^{o}matos celulares, utilizando como exemplo o Jogo da Vida. Ambas implementações visam a redu\c{c}\~{a}o do tempo de processamento para entradas com grades bi-dimensionais com uma ordem elevada ou um grande n\'{u}mero de gera\c{c}\~{o}es. Para descrever o trabalho realizado, o artigo encontra-se organizado da seguinte forma: nas seções \ref{s:paral} e ref{s:algoritmos} descreve-se uma metodologia clássica para paraleliza\c{c}\~{a}o e apresenta-se os algoritmos implementados;  na se\c{c}\~{a}o \ref{s:avaliacao} descreve-se a metodologia utilizada para avaliação do desempenho das implementações; na se\c{c}\~{a}o \ref{s:result} realiza-se a an\'{a}lise dos resultados e a avalia\c{c}\~{a}o dos mesmos e na se\c{c}\~{a}o \ref{s:comc}, por fim, traçam-se as conclus\~{o}es sobre o trabalho desenvolvido.


\section{Metodologia de Paraleliza\c{c}\~{a}o}\label{s:paral}

Dado um problema a ser paralelizado, existe mais de uma forma de realizar a divis\~{a}o do trabalho para que os processos possam realizar o processamento de modo paralelo. Para facilitar e padronizar o desenvolvimento de um algoritmo paralelo, segue-se uma abordagem met\'{o}dica, a qual prov\^{e} mecanismos para avalia\c{c}\~{a}o das poss\'{i}veis alternativas de implementa\c{c}\~{a}o. Esta estrat\'{e}gia que pode ser seguida de um modo geral no desenvolvimento de programas paralelos e \'{e} dividida em quatro est\'{a}gios: particionamento, comunica\c{c}\~{a}o, aglomera\c{c}\~{a}o e mapeamento\cite{foster}. 
%Estas fases ser\~{a}o brevemente explicadas a seguir e as escolhas efetuadas no presente trabalho ser\~{a}o detalhadas na pr\'{o}xima sub-se\c{c}\~{a}o.

A primeira fase deste m\'{e}todo consiste em identificar os pontos potenciais onde o paralelismo possa ser explorado. Esta fase chama-se de fase de \textbf{particionamento} e \'{e} dividida em duas estrat\'{e}gias b\'{a}sicas, de acordo com a solu\c{c}\~{a}o para o problema: particionamento por decomposi\c{c}\~{a}o de dom\'{i}nio ou por decomposi\c{c}\~{a}o funcional.

Na segunda fase do m\'{e}todo utilizado \'{e} analisada a \textbf{comunica\c{c}\~{a}o} necess\'{a}ria a ser realizada entre as tarefas geradas pela fase de particionamento. Embora o projeto dos programas paralelos busque diminuir ao m\'{a}ximo a necessidade de comunica\c{c}\~{a}o entre os processos, dificilmente \'{e} conseguida a elimina\c{c}\~{a}o por completo desta custosa atividade. As estrat\'{e}gias de comunica\c{c}\~{a}o utilizadas neste trabalho s\~{a}o v\'{a}rias e se aplicam a diferentes pontos considerados na implementa\c{c}\~{a}o da solu\c{c}\~{a}o paralela para o problema proposto. 

O pr\'{o}ximo est\'{a}gio do projeto do algoritmo paralelo se chama fase de \textbf{aglomera\c{c}\~{a}o} e visa, em geral, diminuir o n\'{u}mero de tarefas geradas pela fase de particionamento. Esta fase \'{e} de extrema import\^{a}ncia para o desempenho do programa paralelo, pois, caso seja tomada uma decis\~{a}o equivocada na fase de aglomera\c{c}\~{a}o, deixando processos com tempo de comunica\c{c}\~{a}o maiores que o tempo de processamento, o desempenho do programa paralelo poder\'{a} ficar abaixo do desempenho obtido com o programa seqüencial.

Na \'{u}ltima fase, de \textbf{mapeamento}, define-se o computador onde cada tarefa dever\'{a} ser executada. Neste trabalho, esta fase foi executada concomitantemente com a fase de aglomera\c{c}\~{a}o.

\section{Algoritmos Implementados}\label{s:algoritmos}

Para a implementa\c{c}\~{a}o das duas abordagens comparadas neste artigo, utilizamos a estrat\'{e}gia do particionamento por decomposi\c{c}\~{a}o de dom\'{i}nio, onde a \'{a}rea de dados do problema, que \'{e} representada pela grade bi-dimensional, \'{e} dividida entre os processos para que estes realizem o processamento local. A divis\~{a}o, nas duas implementa\c{c}\~{o}es, foi realizada por linhas, ou seja, cada processo envolvido na computa\c{c}\~{a}o recebe uma determinada quantidade de linhas pelas quais ser\'{a} o respons\'{a}vel.

A escolha por esta estrat\'{e}gia justifica-se pelo fato dos dados do problema serem compostos por uma matriz que pode ser facilmente distribu\'{i}da entre os processos. Essa divis\~{a}o deve ser preferencialmente igualit\'{a}ria, para que todos os processadores sejam totalmente aproveitados. Caso haja processadores ociosos ou sobrecarregados devido à má distribuição do trabalho, o desempenho do programa paralelo podem ficar aquém do esperado.

A outra alternativa de particionamento, por decomposi\c{c}\~{a}o funcional, necessita de uma an\'{a}lise sobre a computa\c{c}\~{a}o que deve ser realizada. Para que seja poss\'{i}vel utilizar esta abordagem, \'{e} necess\'{a}rio que se consiga dividir o problema em tarefas independentes, a fim de realizar o particionamento dos dados que ser\~{a}o destinados a cada uma destas. Portanto, de acordo com a descri\c{c}\~{a}o do problema proposto, esta alternativa de particionamento torna-se invi\'{a}vel, pois h\'{a} bastante depend\^{e}ncia entre as computa\c{c}\~{o}es a serem realizadas sobre os dados.

Na fase da comunica\c{c}\~{a}o define-se os pontos cr\'{i}ticos nos quais é necess\'{a}ria a comunica\c{c}\~{a}o entre os processos. O primeiro ponto onde \'{e} necess\'{a}rio que se defina um modo de comunica\c{c}\~{a}o \'{e} ap\'{o}s a leitura dos dados vindos da entrada padr\~{a}o, pois o processo que realiza essa leitura dever\'{a} compartilhar com os outros a matriz que representa o tabuleiro do Jogo da Vida. Ambas implementações utilizam o padrão MPI (\emph{Message Passing Interface})~\cite{mpi} para comunicação entre os processos. No entanto, tem-se nesse ponto uma das diferen\c{c}as b\'{a}sicas entre as duas implementa\c{c}\~{o}es:
\begin{itemize}
\item na primeira implementa\c{c}\~{a}o, chamada de BDMB devido \`{a}s suas caracter\'{i}sticas, um processo realiza a leitura da grade e envia, atrav\'{e}s da chamada \`{a} fun\c{c}\~{a}o de comunica\c{c}\~{a}o coletiva MPI\_Bcast, a matriz inteira para todos os processos;
\item na segunda implementa\c{c}\~{a}o, nomeada de BCMNB tamb\'{e}m devido \`{a}s suas caracter\'{i}sticas de comunica\c{c}\~{a}o, a matriz \'{e} dividida no processo que realiza sua leitura e, atrav\'{e}s de chamadas \`{a} fun\c{c}\~{a}o MPI\_Send, s\~{a}o enviadas as sub-matrizes aos processos para que estes possam realizar seu processamento.
\end{itemize}

Um ponto importante que foi analisado durante a fase de comunica\c{c}\~{a}o \'{e} o compartilhamento de linhas entre os processos durante o c\'{a}lculo das gera\c{c}\~{o}es. De acordo com a defini\c{c}\~{a}o do problema do Jogo da Vida, para que seja calculado um novo valor para um item da matriz, \'{e} necess\'{a}rio que se consulte os valores dos ítens vizinhos a este. Este detalhe traz uma complica\c{c}\~{a}o adicional \`{a} paraleliza\c{c}\~{a}o do problema, pois para que um processo calcule os valores dos ítens de sua primeira linha, \'{e} necess\'{a}rio que este tenha acesso aos valores atualizados da \'{u}ltima linha do processo respons\'{a}vel pela sub-matriz imediatamente acima. Do mesmo modo, para calcular sua última linha, é necessário que o processo disponha da primeira linha da sub-matriz que localiza-se imediatamente abaixo. Esse compartilhamento de dados exige que os processos troquem mensagens entre si a cada c\'{a}lculo de gera\c{c}\~{a}o. 

As duas abordagens seguem estrat\'{e}gias um pouco diferentes com relação à comunicação a cada cálculo de geração. Enquanto a implementa\c{c}\~{a}o BDMB realiza a troca de linhas entre processos atrav\'{e}s de rotinas de envio bloqueantes (MPI\_Send), a implementa\c{c}\~{a}o BCNMB utiliza como recurso rotinas de envio n\~{a}o-bloquantes(MPI\_Isend), para que os processos n\~{a}o fiquem bloqueados durante o envio de suas linhas. A figura \ref{f:esq} ilustra as diferen\c{c}as entre as duas abordagens utilizadas nesse artigo, quanto ao tipo de comunica\c{c}\~{a}o utilizado.

\begin{figure}[ht]
\centering
\includegraphics[width=12cm]{img/esquema.png}
\caption{Diagrama da implementa\c{c}\~{a}o dos algoritmos}
\label{f:esq}
\end{figure}

A \'{u}ltima fase da execu\c{c}\~{a}o onde deve ser realizada comunica\c{c}\~{a}o entre os processos \'{e} quando os processos tiverem terminado de executar seus c\'{a}lculos, quando devem devolver suas sub-matrizes para que um processo coordenador possa realizar a montagem da matriz de sa\'{i}da do programa.

%Durante a fase de aglomera\c{c}\~{a}o, decidimos aumentar a m\'{a}ximo o tamanho da sub-matriz de cada processo, para que a rela\c{c}\~{a}o existente entre comunica\c{c}\~{a}o e computa\c{c}\~{a}o traga vantagens para o desempenho do programa.

\section{Metodologia de Avalia\c{c}\~{a}o de Desempenho}\label{s:avaliacao}

A fim de avaliar e comparar o desempenho das duas implementações descritas acima, realizou-se uma série de execuções paralelas variando-se os parâmetros de entrada e o número de computadores utilizados.
 
Os testes foram executados no N\'{u}cleo da Ci\^{e}ncia da Computa\c{c}\~{a}o (NCC) da UFSM, em computadores Intel(R) Pentium(R) 4 de 2GHz, com 512Mb de mem\'{o}ria RAM, rodando o sistema operacional GNU/Linux vers\~{a}o 2.6.19, com distribui\c{c}\~{a}o Gentoo. Para a troca de mensagens entre as m\'{a}quinas foi utilizada uma rede Fast Ethernet.

Para a realiza\c{c}\~{a}o dos testes foram criados arquivos com grades de 20 linhas por 20 colunas (20x20), 500 linhas por 500 colunas (500x500) e 2500 linhas por 2500 colunas (2500x2500), todos com 5000 gera\c{c}\~{o}es (passos de tempo). Foram utilizados os mesmos dados para as diferentes implementa\c{c}\~{o}es.

A execu\c{c}\~{a}o para a tomada dos tempos foi realizada com 1 processador  (execu\c{c}\~{a}o serial) e de 2 a 7 processadores. Para ter uma melhor confiabilidade nos resultados, todos os testes foram executados 10 vezes e ent\~{a}o foi calculada a m\'{e}dia dos 5 melhores tempos, exceto quando os tempos medidos variavam 0,2 segundos da m\'{e}dia. Nesse \'{u}ltimo caso, todos os tempos que estavam nessa margem de toler\^{a}ncia eram levados em conta para o calculo da m\'{e}dia para dado n\'{u}mero de processadores.

Essa metodologia foi adotada devido \`{a} grande varia\c{c}\~{a}o apresentada nos tempos para uma mesma matriz e um mesmo n\'{u}mero de processadores. Esse problema deve-se ao fato das m\'{a}quinas utilizadas n\~{a}o serem exclusivas para teste, podendo sofrer influ\^{e}ncia de outros usu\'{a}rios. Para complementar a análise dos resultados, calculou-se a aceleração (\emph{speed-up})\footnote{O \emph{speed-up} para N processadores é dado pela relação entre o tempo de execução seqüencial e o tempo de execução paralela em N processadores~\cite{foster}.}.


\section{Resultados}\label{s:result}
Para ambas solu\c{c}\~{o}es paralelas, o tempo de execu\c{c}\~{a}o da matriz 20x20 foi pior que tempo do programa seq\"{u}encial, o que pode ser facilmente verificado pelo gr\'{a}fico de \emph{speed-up} mostrado na figura \ref{f:20x20}.  Isso deve-se ao fato de que os programas paralelos gastaram mais tempo com comunica\c{c}\~{a}o entre os processos do que propriamente processando o algoritmo. Entretanto, o algoritmo BDMB obteve um desempenho ligeiramente superior pelo fato de ter gasto menos tempo na comunicação para distribuição das tarefas, como pode ser visto na tabela da figura \ref{f:20x20}.

\begin{figure}[ht]
\centering
\includegraphics[width=12cm]{img/20x20.png}
\caption{Gr\'{a}fico do \emph{speed-up} da matriz 20x20 e tabela comparativa de tempo gasto para distribuir as tarefas.}
\label{f:20x20}
\end{figure}

No caso da execu\c{c}\~{a}o da matriz 500x500 e 2500x2500, podemos analisar atrav\'{e}s dos gr\'{a}ficos da figuras \ref{f:500x500} e \ref{f:2500x2500}, respectivamente, que a execu\c{c}\~{a}o BDMB obteve um melhor desempenho.

\begin{figure}[ht]
\centering
\includegraphics[width=12cm]{img/500x500.png}
\caption{Gr\'{a}fico do \emph{speed-up} da matriz 500x500 e tabela comparativa de tempo gasto para distribuir as tarefas.}
\label{f:500x500}
\end{figure}

\begin{figure}[hbt]
\centering
\includegraphics[width=12cm]{img/2500x2500.png}
\caption{Gr\'{a}fico do Speedup da matriz 2500x2500 e tabela comparativa de tempo gasto para distribuir as tarefas.}
\label{f:2500x2500}
\end{figure}

Para a matriz 500x500, isso \'{e} evidenciado pela tabela da figura \ref{f:500x500}, que mostra que o tempo gasto pelo BDMB na comunica\c{c}\~{a}o e distribuição das tarefas \'{e} menor que a implementa\c{c}\~{a}o que utiliza a estrat\'{e}gia BCMNB. Essa diferen\c{c}a de desempenho em rela\c{c}\~{a}o à implementa\c{c}\~{a}o BCMNB deve-se principalmente pelas caracter\'{i}sticas da rede Fast Ethernet. Esta rede de forma geral n\~{a}o apresenta um bom desempenho, principalmente em rela\c{c}\~{a}o \`{a} sua lat\^{e}ncia. Nesse sentido, o BDMB se favorece ao enviar somente uma \'{u}nica mensagem para todas as m\'{a}quinas e cada m\'{a}quina separando uma sub-matriz para efetuar seu processamento. Como o BCNMB divide a matriz em um nodo centralizado, o mesmo demora para redistribuir as tarefas aos demais processos.  Desse modo, o BCMNB perde desempenho pelo fato da rede possuir uma lat\^{e}ncia relativamente alta.

Contudo, ainda que o algoritmo BDMB apresente um melhor \emph{speed-up} para a matriz 2500x2500, o desempenho do algoritmo BCMNB melhorou consideravelmente. Essa melhora  deve-se ao fato da matriz 2500x2500 ocupar proximadamente 12 Mb de mem\'{o}ria RAM, sendo que para o tr\'{a}fego de uma matriz t\~{a}o grande utilizou-se diversos datagramas. Nessa situação essa abordagem se mostrou eficiente, conseguindo obter desempenho mais pr\'{o}ximo da implementa\c{c}\~{a}o BDMB.

Há também que se ressaltar que, neste último caso, a relação entre o tempo de computação e o tempo de comunicação é maior do que nos outros casos, já que a matriz é de grande dimensão e cada processo calcula sub-matrizes de tamanho significativo. Este fator beneficia ambas implementações, como se pode confirmar através dos resultados obtidos.

%Dessa maneira, \'{e} poss\'{i}vel verificar que o maior problema da implementa\c{c}\~{a}o BCMNB \'{e} o escalonamento, o qual em grande parte das vezes deixa algum processo sobrecarregado e os outros tendo que processar menos carga.  Uma reimplementa\c{c}\~{a}o do algoritmo de escalonamento poder\'{a} produzir resultados mais pr\'{o}ximos do BDMB.


\section{Conclus\~{a}o}\label{s:comc}
Este artigo apresentou uma compara\c{c}\~{a}o entre a implemen\c{c}\~{a}o serial e duas implementa\c{c}\~{o}es paralelas de um problema do tipo aut\^{o}mato celular, utilizando com exemplo o Jogo da Vida. Com este trabalho, demosntra-se que a paraleliza\c{c}\~{a}o de aut\^{o}matos pode auxiliar na obtenc\~{a}o de resultados de forma mais r\'{a}pida, em casos de entradas muito grandes. Isso mesmo com implementa\c{c}\~{o}es diferenciadas.

A compara\c{c}\~{a}o dos algoritmos demosntra que, para matrizes de tamanho intermedi\'{a}rio, eles apresentam algumas diferen\c{c}\~{a}o no tempo de execu\c{c}\~{a}o, mas à medida que aumenta a entrada, seus resultados aproximam-se. Esse resultado confirma que a paraleliza\c{c}\~{a}o tende a diminuir o tempo de processamento, resultando em respostas mais r\'{a}pidas, independente de qual dos dois algoritmos tenha sido utilizado.

No entanto, constata-se que a divisão ideal de cada matriz deve levar em considera\c{c}\~{a}o o n\'{u}mero de processadores e a comunica\c{c}\~{a}o da rede, pois, do contr\'{a}rio, nem sempre o aumento do n\'{u}mero de processadores levar\'{a} \`{a} uma melhora no tempo de processamento, podendo ocorrer uma piora em alguns casos.

\bibliographystyle{ref/sbc}
\bibliography{ref/referencias}

\end{document}

%% <!-- Local IspellDict: brasileiro -->
%% <!-- Local Variables: -->
%% <!-- mode:flyspell -->
%% <!-- End: -->